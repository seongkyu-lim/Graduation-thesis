{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrt22607MdxeeQJ7SkV9bp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e72051cd910444ba294fc9e8b2f1550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f82ef7698404894aeb07ea98b00a03f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2530ed7c921e464f9387d64c5ced1935",
              "IPY_MODEL_8969ebbbb1aa47fa9e11fa38b94de13c",
              "IPY_MODEL_7b86a15784ce4ef2bd609d0d3b7cd4b5"
            ]
          }
        },
        "7f82ef7698404894aeb07ea98b00a03f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2530ed7c921e464f9387d64c5ced1935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a4afb1ce4ee45ecbfdb2caed3c30894",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ea8e31f26f34350862a4bff48a5bfdc"
          }
        },
        "8969ebbbb1aa47fa9e11fa38b94de13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf4aa1b0b461498bbdf3e5e9ef60fc77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6984509,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6984509,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_528551ee00eb47e599054b3f5e54d83b"
          }
        },
        "7b86a15784ce4ef2bd609d0d3b7cd4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d38f517161a4f76826bb2cae83ccb28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.66M/6.66M [00:00&lt;00:00, 14.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d1b146a428b4cd8a4e4a199856ccecb"
          }
        },
        "4a4afb1ce4ee45ecbfdb2caed3c30894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ea8e31f26f34350862a4bff48a5bfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf4aa1b0b461498bbdf3e5e9ef60fc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "528551ee00eb47e599054b3f5e54d83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d38f517161a4f76826bb2cae83ccb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d1b146a428b4cd8a4e4a199856ccecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongkyu-lim/Graduation-thesis/blob/master/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-fP7Sa-zc1F",
        "outputId": "7221df89-3c61-45e2-ef46-f1b51cfb031a"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2McCEnNi39Kn",
        "outputId": "69bffcab-e74d-493c-e47e-973122b22a02"
      },
      "source": [
        "# mount gdrive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgPRo9xX9_4i"
      },
      "source": [
        "#Inference\n",
        "이미 trained된 모델인 yolov5x,s,m,l 중 성능이 가장 좋은 xlarge모델로 inference 해보았습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgK_Du19k3sl",
        "outputId": "cde8a2ba-ecfe-48eb-b7d9-3630adc3e9ef"
      },
      "source": [
        "import torch\n",
        "\n",
        "%ls\n",
        "\n",
        "#절대경로로 읿력해주어야 파일 위치 인식한다.\n",
        "!python /content/yolov5/detect.py --weight yolov5x.pt --img 1280 --conf 0.4 --save-conf --save-txt --save-crop --source /content/yolov5/data/images/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTRIBUTING.md  Dockerfile  LICENSE    \u001b[0m\u001b[01;32mrequirements.txt\u001b[0m*  \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/            export.py   \u001b[01;34mmodels\u001b[0m/    train.py           val.py\n",
            "detect.py        hubconf.py  README.md  tutorial.ipynb\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 31.8MB/s]\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5x.pt'], source=/content/yolov5/data/images/train, imgsz=[1280, 1280], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-438-g27a4736 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 168M/168M [00:01<00:00, 93.1MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87730285 parameters, 0 gradients\n",
            "image 1/45 /content/yolov5/data/images/train/frame0.jpg: 736x1280 9 persons, Done. (0.125s)\n",
            "image 2/45 /content/yolov5/data/images/train/frame1.jpg: 736x1280 14 persons, Done. (0.123s)\n",
            "image 3/45 /content/yolov5/data/images/train/frame10.jpg: 736x1280 10 persons, 1 chair, Done. (0.124s)\n",
            "image 4/45 /content/yolov5/data/images/train/frame11.jpg: 736x1280 11 persons, 2 chairs, Done. (0.123s)\n",
            "image 5/45 /content/yolov5/data/images/train/frame12.jpg: 736x1280 2 persons, Done. (0.124s)\n",
            "image 6/45 /content/yolov5/data/images/train/frame13.jpg: 736x1280 2 persons, Done. (0.124s)\n",
            "image 7/45 /content/yolov5/data/images/train/frame14.jpg: 736x1280 2 persons, Done. (0.125s)\n",
            "image 8/45 /content/yolov5/data/images/train/frame15.jpg: 736x1280 3 persons, Done. (0.125s)\n",
            "image 9/45 /content/yolov5/data/images/train/frame16.jpg: 736x1280 14 persons, 1 sink, Done. (0.126s)\n",
            "image 10/45 /content/yolov5/data/images/train/frame17.jpg: 736x1280 19 persons, 1 baseball glove, Done. (0.126s)\n",
            "image 11/45 /content/yolov5/data/images/train/frame18.jpg: 736x1280 20 persons, 1 baseball glove, Done. (0.125s)\n",
            "image 12/45 /content/yolov5/data/images/train/frame19.jpg: 736x1280 21 persons, Done. (0.125s)\n",
            "image 13/45 /content/yolov5/data/images/train/frame2.jpg: 736x1280 14 persons, Done. (0.124s)\n",
            "image 14/45 /content/yolov5/data/images/train/frame20.jpg: 736x1280 22 persons, 1 sports ball, 1 baseball glove, Done. (0.125s)\n",
            "image 15/45 /content/yolov5/data/images/train/frame21.jpg: 736x1280 22 persons, 1 sports ball, Done. (0.124s)\n",
            "image 16/45 /content/yolov5/data/images/train/frame22.jpg: 736x1280 21 persons, 1 sports ball, Done. (0.124s)\n",
            "image 17/45 /content/yolov5/data/images/train/frame23.jpg: 736x1280 21 persons, 1 sports ball, 1 baseball glove, Done. (0.125s)\n",
            "image 18/45 /content/yolov5/data/images/train/frame24.jpg: 736x1280 20 persons, 1 sports ball, Done. (0.124s)\n",
            "image 19/45 /content/yolov5/data/images/train/frame25.jpg: 736x1280 18 persons, 1 sports ball, Done. (0.124s)\n",
            "image 20/45 /content/yolov5/data/images/train/frame26.jpg: 736x1280 18 persons, 2 sports balls, Done. (0.124s)\n",
            "image 21/45 /content/yolov5/data/images/train/frame27.jpg: 736x1280 16 persons, 1 sports ball, Done. (0.124s)\n",
            "image 22/45 /content/yolov5/data/images/train/frame28.jpg: 736x1280 14 persons, 2 baseball gloves, Done. (0.124s)\n",
            "image 23/45 /content/yolov5/data/images/train/frame29.jpg: 736x1280 15 persons, 1 baseball glove, Done. (0.124s)\n",
            "image 24/45 /content/yolov5/data/images/train/frame3.jpg: 736x1280 16 persons, Done. (0.124s)\n",
            "image 25/45 /content/yolov5/data/images/train/frame30.jpg: 736x1280 14 persons, Done. (0.125s)\n",
            "image 26/45 /content/yolov5/data/images/train/frame31.jpg: 736x1280 13 persons, Done. (0.125s)\n",
            "image 27/45 /content/yolov5/data/images/train/frame32.jpg: 736x1280 13 persons, Done. (0.125s)\n",
            "image 28/45 /content/yolov5/data/images/train/frame33.jpg: 736x1280 15 persons, 1 tennis racket, Done. (0.124s)\n",
            "image 29/45 /content/yolov5/data/images/train/frame34.jpg: 736x1280 16 persons, Done. (0.123s)\n",
            "image 30/45 /content/yolov5/data/images/train/frame35.jpg: 736x1280 14 persons, Done. (0.126s)\n",
            "image 31/45 /content/yolov5/data/images/train/frame36.jpg: 736x1280 13 persons, Done. (0.125s)\n",
            "image 32/45 /content/yolov5/data/images/train/frame37.jpg: 736x1280 15 persons, 1 sports ball, Done. (0.124s)\n",
            "image 33/45 /content/yolov5/data/images/train/frame38.jpg: 736x1280 14 persons, 1 sports ball, 1 baseball glove, Done. (0.126s)\n",
            "image 34/45 /content/yolov5/data/images/train/frame39.jpg: 736x1280 13 persons, 1 sports ball, 1 tennis racket, Done. (0.125s)\n",
            "image 35/45 /content/yolov5/data/images/train/frame4.jpg: 736x1280 16 persons, Done. (0.125s)\n",
            "image 36/45 /content/yolov5/data/images/train/frame40.jpg: 736x1280 16 persons, 1 sports ball, 1 baseball glove, 2 tennis rackets, Done. (0.127s)\n",
            "image 37/45 /content/yolov5/data/images/train/frame41.jpg: 736x1280 14 persons, 1 sports ball, 1 tennis racket, Done. (0.124s)\n",
            "image 38/45 /content/yolov5/data/images/train/frame42.jpg: 736x1280 13 persons, Done. (0.123s)\n",
            "image 39/45 /content/yolov5/data/images/train/frame43.jpg: 736x1280 11 persons, 1 sports ball, Done. (0.124s)\n",
            "image 40/45 /content/yolov5/data/images/train/frame44.jpg: 736x1280 16 persons, 1 sports ball, Done. (0.124s)\n",
            "image 41/45 /content/yolov5/data/images/train/frame5.jpg: 736x1280 15 persons, Done. (0.125s)\n",
            "image 42/45 /content/yolov5/data/images/train/frame6.jpg: 736x1280 16 persons, Done. (0.126s)\n",
            "image 43/45 /content/yolov5/data/images/train/frame7.jpg: 736x1280 14 persons, Done. (0.124s)\n",
            "image 44/45 /content/yolov5/data/images/train/frame8.jpg: 736x1280 13 persons, Done. (0.125s)\n",
            "image 45/45 /content/yolov5/data/images/train/frame9.jpg: 736x1280 14 persons, 1 chair, Done. (0.126s)\n",
            "Speed: 0.9ms pre-process, 124.6ms inference, 1.7ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "45 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-e5Od7-cmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "eb2dc09c-c7fe-4a40-8b38-cd747161a7f1"
      },
      "source": [
        "# 이미지로 확인해보기. \n",
        "# 영상으로 저장되서 불가능.\n",
        "Image(filename='runs/detect/exp/', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-61d069bb73cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 이미지로 확인해보기.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runs/detect/exp/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ACCEPTABLE_EMBEDDINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot embed the '%s' image format\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot embed the 'runs/detect/exp/' image format"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQPXXNVS-ixd"
      },
      "source": [
        "# inference된 영상 다운로드 받기.\n",
        "from google.colab import files\n",
        "files.download('./inference/output/ARS-CHEL-0.mp4')\n",
        "\n",
        "# 또는 구글드라이브로 옮겨서 확인하기."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NfRwHhu-555"
      },
      "source": [
        "#Train\n",
        "\n",
        "  train하기\n",
        "\n",
        "##Challenge\n",
        "\n",
        "- 양 팀을 다르게 인식해야한다.\n",
        "- 심판과 공또한 인식해야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bv2ETKPbnby"
      },
      "source": [
        "##1.opencv를 활용한 영상 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWWYgNVXbyAj",
        "outputId": "29005121-3fce-4fa5-873a-9a2fb42223e6"
      },
      "source": [
        "%pip install opencv-python\n",
        "%pip install numpy\n",
        "%pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oRZMJE4hbzNu",
        "outputId": "b513e627-d94f-412d-d077-3082104164b2"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "__author__ = 'Seran'\n",
        " \n",
        "import cv2\n",
        " \n",
        "# 영상의 의미지를 연속적으로 캡쳐할 수 있게 하는 class\n",
        "vidcap = cv2.VideoCapture('/content/drive/MyDrive/졸업논문/20210822-ARS-CHE-EPL_1-1080.mkv')\n",
        " \n",
        "count = 0\n",
        "\n",
        "while(vidcap.isOpened()):\n",
        "    ret, image = vidcap.read()\n",
        " \n",
        "    if(int(vidcap.get(1)) % 200 == 0):\n",
        "        print('Saved frame number : ' + str(int(vidcap.get(1))))\n",
        "        cv2.imwrite(\"/content/yolov5/data/images/train/frame%d.jpg\" % count, image) # data/images/train에 저장.\n",
        "        print('Saved frame%d.jpg' % count)\n",
        "        count += 1\n",
        " \n",
        "vidcap.release()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved frame number : 200\n",
            "Saved frame0.jpg\n",
            "Saved frame number : 400\n",
            "Saved frame1.jpg\n",
            "Saved frame number : 600\n",
            "Saved frame2.jpg\n",
            "Saved frame number : 800\n",
            "Saved frame3.jpg\n",
            "Saved frame number : 1000\n",
            "Saved frame4.jpg\n",
            "Saved frame number : 1200\n",
            "Saved frame5.jpg\n",
            "Saved frame number : 1400\n",
            "Saved frame6.jpg\n",
            "Saved frame number : 1600\n",
            "Saved frame7.jpg\n",
            "Saved frame number : 1800\n",
            "Saved frame8.jpg\n",
            "Saved frame number : 2000\n",
            "Saved frame9.jpg\n",
            "Saved frame number : 2200\n",
            "Saved frame10.jpg\n",
            "Saved frame number : 2400\n",
            "Saved frame11.jpg\n",
            "Saved frame number : 2600\n",
            "Saved frame12.jpg\n",
            "Saved frame number : 2800\n",
            "Saved frame13.jpg\n",
            "Saved frame number : 3000\n",
            "Saved frame14.jpg\n",
            "Saved frame number : 3200\n",
            "Saved frame15.jpg\n",
            "Saved frame number : 3400\n",
            "Saved frame16.jpg\n",
            "Saved frame number : 3600\n",
            "Saved frame17.jpg\n",
            "Saved frame number : 3800\n",
            "Saved frame18.jpg\n",
            "Saved frame number : 4000\n",
            "Saved frame19.jpg\n",
            "Saved frame number : 4200\n",
            "Saved frame20.jpg\n",
            "Saved frame number : 4400\n",
            "Saved frame21.jpg\n",
            "Saved frame number : 4600\n",
            "Saved frame22.jpg\n",
            "Saved frame number : 4800\n",
            "Saved frame23.jpg\n",
            "Saved frame number : 5000\n",
            "Saved frame24.jpg\n",
            "Saved frame number : 5200\n",
            "Saved frame25.jpg\n",
            "Saved frame number : 5400\n",
            "Saved frame26.jpg\n",
            "Saved frame number : 5600\n",
            "Saved frame27.jpg\n",
            "Saved frame number : 5800\n",
            "Saved frame28.jpg\n",
            "Saved frame number : 6000\n",
            "Saved frame29.jpg\n",
            "Saved frame number : 6200\n",
            "Saved frame30.jpg\n",
            "Saved frame number : 6400\n",
            "Saved frame31.jpg\n",
            "Saved frame number : 6600\n",
            "Saved frame32.jpg\n",
            "Saved frame number : 6800\n",
            "Saved frame33.jpg\n",
            "Saved frame number : 7000\n",
            "Saved frame34.jpg\n",
            "Saved frame number : 7200\n",
            "Saved frame35.jpg\n",
            "Saved frame number : 7400\n",
            "Saved frame36.jpg\n",
            "Saved frame number : 7600\n",
            "Saved frame37.jpg\n",
            "Saved frame number : 7800\n",
            "Saved frame38.jpg\n",
            "Saved frame number : 8000\n",
            "Saved frame39.jpg\n",
            "Saved frame number : 8200\n",
            "Saved frame40.jpg\n",
            "Saved frame number : 8400\n",
            "Saved frame41.jpg\n",
            "Saved frame number : 8600\n",
            "Saved frame42.jpg\n",
            "Saved frame number : 8800\n",
            "Saved frame43.jpg\n",
            "Saved frame number : 9000\n",
            "Saved frame44.jpg\n",
            "Saved frame number : 9200\n",
            "Saved frame45.jpg\n",
            "Saved frame number : 9400\n",
            "Saved frame46.jpg\n",
            "Saved frame number : 9600\n",
            "Saved frame47.jpg\n",
            "Saved frame number : 9800\n",
            "Saved frame48.jpg\n",
            "Saved frame number : 10000\n",
            "Saved frame49.jpg\n",
            "Saved frame number : 10200\n",
            "Saved frame50.jpg\n",
            "Saved frame number : 10400\n",
            "Saved frame51.jpg\n",
            "Saved frame number : 10600\n",
            "Saved frame52.jpg\n",
            "Saved frame number : 10800\n",
            "Saved frame53.jpg\n",
            "Saved frame number : 11000\n",
            "Saved frame54.jpg\n",
            "Saved frame number : 11200\n",
            "Saved frame55.jpg\n",
            "Saved frame number : 11400\n",
            "Saved frame56.jpg\n",
            "Saved frame number : 11600\n",
            "Saved frame57.jpg\n",
            "Saved frame number : 11800\n",
            "Saved frame58.jpg\n",
            "Saved frame number : 12000\n",
            "Saved frame59.jpg\n",
            "Saved frame number : 12200\n",
            "Saved frame60.jpg\n",
            "Saved frame number : 12400\n",
            "Saved frame61.jpg\n",
            "Saved frame number : 12600\n",
            "Saved frame62.jpg\n",
            "Saved frame number : 12800\n",
            "Saved frame63.jpg\n",
            "Saved frame number : 13000\n",
            "Saved frame64.jpg\n",
            "Saved frame number : 13200\n",
            "Saved frame65.jpg\n",
            "Saved frame number : 13400\n",
            "Saved frame66.jpg\n",
            "Saved frame number : 13600\n",
            "Saved frame67.jpg\n",
            "Saved frame number : 13800\n",
            "Saved frame68.jpg\n",
            "Saved frame number : 14000\n",
            "Saved frame69.jpg\n",
            "Saved frame number : 14200\n",
            "Saved frame70.jpg\n",
            "Saved frame number : 14400\n",
            "Saved frame71.jpg\n",
            "Saved frame number : 14600\n",
            "Saved frame72.jpg\n",
            "Saved frame number : 14800\n",
            "Saved frame73.jpg\n",
            "Saved frame number : 15000\n",
            "Saved frame74.jpg\n",
            "Saved frame number : 15200\n",
            "Saved frame75.jpg\n",
            "Saved frame number : 15400\n",
            "Saved frame76.jpg\n",
            "Saved frame number : 15600\n",
            "Saved frame77.jpg\n",
            "Saved frame number : 15800\n",
            "Saved frame78.jpg\n",
            "Saved frame number : 16000\n",
            "Saved frame79.jpg\n",
            "Saved frame number : 16200\n",
            "Saved frame80.jpg\n",
            "Saved frame number : 16400\n",
            "Saved frame81.jpg\n",
            "Saved frame number : 16600\n",
            "Saved frame82.jpg\n",
            "Saved frame number : 16800\n",
            "Saved frame83.jpg\n",
            "Saved frame number : 17000\n",
            "Saved frame84.jpg\n",
            "Saved frame number : 17200\n",
            "Saved frame85.jpg\n",
            "Saved frame number : 17400\n",
            "Saved frame86.jpg\n",
            "Saved frame number : 17600\n",
            "Saved frame87.jpg\n",
            "Saved frame number : 17800\n",
            "Saved frame88.jpg\n",
            "Saved frame number : 18000\n",
            "Saved frame89.jpg\n",
            "Saved frame number : 18200\n",
            "Saved frame90.jpg\n",
            "Saved frame number : 18400\n",
            "Saved frame91.jpg\n",
            "Saved frame number : 18600\n",
            "Saved frame92.jpg\n",
            "Saved frame number : 18800\n",
            "Saved frame93.jpg\n",
            "Saved frame number : 19000\n",
            "Saved frame94.jpg\n",
            "Saved frame number : 19200\n",
            "Saved frame95.jpg\n",
            "Saved frame number : 19400\n",
            "Saved frame96.jpg\n",
            "Saved frame number : 19600\n",
            "Saved frame97.jpg\n",
            "Saved frame number : 19800\n",
            "Saved frame98.jpg\n",
            "Saved frame number : 20000\n",
            "Saved frame99.jpg\n",
            "Saved frame number : 20200\n",
            "Saved frame100.jpg\n",
            "Saved frame number : 20400\n",
            "Saved frame101.jpg\n",
            "Saved frame number : 20600\n",
            "Saved frame102.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9ee139872013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss3BxYArb4a_"
      },
      "source": [
        "%rm -rf /content/yolov5/data/images/train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWtOONSVb40i"
      },
      "source": [
        "## 2.yolov5로 train 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnqPxuyWc7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2e72051cd910444ba294fc9e8b2f1550",
            "7f82ef7698404894aeb07ea98b00a03f",
            "2530ed7c921e464f9387d64c5ced1935",
            "8969ebbbb1aa47fa9e11fa38b94de13c",
            "7b86a15784ce4ef2bd609d0d3b7cd4b5",
            "4a4afb1ce4ee45ecbfdb2caed3c30894",
            "4ea8e31f26f34350862a4bff48a5bfdc",
            "cf4aa1b0b461498bbdf3e5e9ef60fc77",
            "528551ee00eb47e599054b3f5e54d83b",
            "4d38f517161a4f76826bb2cae83ccb28",
            "4d1b146a428b4cd8a4e4a199856ccecb"
          ]
        },
        "outputId": "a243c993-26fc-48f4-92b1-db397f441bb4"
      },
      "source": [
        "# Download COCO128\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e72051cd910444ba294fc9e8b2f1550",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8fYRWV--4wX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b863ced1-9f23-425b-bb81-49e6e443cd11"
      },
      "source": [
        "\n",
        "'''\n",
        "# Tensorboard  (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train\n",
        "'''\n",
        "# Weights & Biases(wandb)  (optional)\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 62.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 69.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msJmk4ZQrQsT",
        "outputId": "57bcced6-db00-40c0-e098-8fd13808aca1"
      },
      "source": [
        "#구글 드라이브에서 yolo모델 데이터셋 폴더로 커스텀 데이터 이동.\n",
        "%mv /content/drive/MyDrive/졸업논문/train /content/yolov5/data/images\n",
        "%mv /content/drive/MyDrive/졸업논문/train_labels /content/yolov5/data/labels\n",
        "%mv /content/drive/MyDrive/졸업논문/dataset.yaml /content/yolov5/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/drive/MyDrive/졸업논문/train': No such file or directory\n",
            "mv: cannot stat '/content/drive/MyDrive/졸업논문/train_labels': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsPscZU--40o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c545b6b-23bc-44d7-d836-0a1e8ab392e9"
      },
      "source": [
        "# dataset.yaml에 훈련, valid를 위한 데이터셋 저장 경로 정보 있음.\n",
        "# dataset.yaml에 경로는 절대경로로\n",
        "!python train.py --img 640 --batch 16 --epochs 5 --data dataset.yaml --weights yolov5x.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 27.6MB/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseongkyu\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=dataset.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-449-g9ef9494 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mamber-durian-10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/seongkyu/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/seongkyu/YOLOv5/runs/1kpr5bf9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20210919_061853-1kpr5bf9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 613, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 511, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 87, in train\n",
            "    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\n",
            "  File \"/content/yolov5/utils/loggers/__init__.py\", line 62, in __init__\n",
            "    self.wandb = WandbLogger(self.opt, run_id)\n",
            "  File \"/content/yolov5/utils/loggers/wandb/wandb_utils.py\", line 179, in __init__\n",
            "    self.data_dict = check_wandb_dataset(opt.data)\n",
            "  File \"/content/yolov5/utils/loggers/wandb/wandb_utils.py\", line 52, in check_wandb_dataset\n",
            "    data_dict['val'].startswith(WANDB_ARTIFACT_PREFIX))\n",
            "KeyError: 'val'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 840\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/yolov5/wandb/run-20210919_061853-1kpr5bf9/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/yolov5/wandb/run-20210919_061853-1kpr5bf9/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mamber-durian-10\u001b[0m: \u001b[34mhttps://wandb.ai/seongkyu/YOLOv5/runs/1kpr5bf9\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnDwKkSN-47A"
      },
      "source": [
        "%rm -rf /content/yolov5/data/labels/train \n",
        "%rm -rf /content/yiolov5/data/labels/valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAoPKEvr-498"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "873I5mEqp_UG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}